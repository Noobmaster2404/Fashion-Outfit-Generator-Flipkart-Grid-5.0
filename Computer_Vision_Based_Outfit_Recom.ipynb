#Working prototype idea taken from Computer_Vision_Based_Outfit_Recommendation by huangemma26

#user inputs the entire Dataset
#first step is to generate all posible outfits
#Then we group similar outfits using embedding
#then predict scores for each outfit based on their similarity scores
#Returns the best outfit from each group
#shows the best recommendation results

import pandas as pd
import numpy as np

import keras
from keras import backend as K
K.set_image_dim_ordering('th')
from keras.models import Model, model_from_json
from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Input
from keras.layers.merge import Concatenate
from keras.layers.core import Flatten, Dense, Dropout, Activation
from keras.preprocessing.sequence import pad_sequences
from keras.callbacks import EarlyStopping

import pickle

input_layer = Input(shape=(3,64,64))

conv1 = Conv2D(496, (3, 3), activation='relu', padding='same')(input_layer)
pool1 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv1)
conv2 = Conv2D(248, (3, 3), activation='relu', padding='same')(pool1)
pool2 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv2)
conv3 = Conv2D(124, (3, 3), activation='relu', padding='same')(pool2)
pool3 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv3)
conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool3)
pool4 = MaxPooling2D(pool_size=(2, 2), padding='same')(conv4)
conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(pool4)
pool5 = MaxPooling2D((2, 2), padding='same')(conv5)
conv6 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool5)
pool6 = MaxPooling2D((2, 2), padding='same')(conv6)
conv7 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool6)
pool7 = MaxPooling2D((2, 2), padding='same')(conv7)

encoded = Flatten(name = 'encoded')(pool7)

conv8 = Conv2D(16, (3, 3), activation='relu', padding='same')(pool7) 
up1 = UpSampling2D((2,2))(conv8)
conv9 = Conv2D(16, (3, 3), activation='relu', padding='same')(up1) 
up2 = UpSampling2D((2,2))(conv9)
conv10 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2) 
up3 = UpSampling2D((2,2))(conv10) 
conv11 = Conv2D(64, (3, 3), activation='relu', padding='same')(up3)
up4 = UpSampling2D((2,2))(conv11)
conv12 = Conv2D(124, (3, 3), activation='relu', padding='same')(up4)
up5 = UpSampling2D((2,2))(conv12) 
conv13 = Conv2D(248, (3, 3), activation='relu', padding='same')(up5)
up6 = UpSampling2D((1, 1))(conv13)
conv14 = Conv2D(496, (3, 3), activation='relu', padding='same')(up6)
up7 = UpSampling2D((2, 2))(conv14)

decoded = Conv2D(3, (5, 5), activation='sigmoid', padding='same')(up7)
print ('shape of decoded', K.int_shape(decoded))

autoencoder = Model(input_layer, decoded)

encoder = Model(input_layer, encoded)

json_autoencoder = autoencoder.to_json()
json_encoder = encoder.to_json()

early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1, mode='auto')

item = ['dress','top','pullover','outerwear','bottom','shoe','bag']

for i in range(1):
    autoencoder = model_from_json(json_autoencoder)
    encoder = model_from_json(json_encoder)
    
    path = '../small_image_vectors/' + item[i] + '.pkl'
    with open(path, 'rb') as picklefile: 
        features = pickle.load(picklefile)
    features = features/255
    
    autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')
    print('Fitting model '+str(i+1))
    autoencoder.fit(features, features, epochs=400, batch_size=100, validation_split=.15, callbacks=[early_stopping])
    
    autoencoder_name = item[i] + '_model.h5'
    autoencoder.save(autoencoder_name)
    encoder_name = item[i] + 'embedding_model.h5'
    encoder.save(encoder_name)
    
    del(features)
    del(autoencoder)
    del(encoder)